{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Final Project: Hazardous N.E.O. Classifier"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "NOTE: A summary will be provided at the bottom of the notebook for ease of grading."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Objective and Overview"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this notebook, we will be training and evaluating several different models: 3 logistic regression classifiers, 2 SVM classifiers, and a random forest classifier.\n",
    "\n",
    "Since we are training multiple logistic regression and SVM classifiers, we will identify which performs the best to compare with the other model types.\n",
    "\n",
    "Our goal is to identify which model type performs best on the dataset in terms of run time and f1-score.\n",
    "\n",
    "The dataset we will be using is the [\"NASA | Nearest Earth Objects (1910-2024)\"](https://www.kaggle.com/datasets/ivansher/nasa-nearest-earth-objects-1910-2024) dataset from Kaggle. This dataset provides 8 features, and a binary classification as the target label, indicating whether or not the object was deemed \"hazardous\". A more detailed description is provided in the \"Loading and Describing the Dataset\" subsection within the \"Preparation\" section."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Preparation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Import necessary libraries and define some helper functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "# for visualization\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This first function will help load our performance metrics into a `scores` dictionary for easy referencing and plotting."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "def allocate_report_metrics(fold: int, scores: dict, report: dict, accuracy, auc):\n",
    "    scores.setdefault('fold', []).append(fold)\n",
    "    scores.setdefault('precision', []).append(report['1']['precision'])\n",
    "    scores.setdefault('recall', []).append(report['1']['recall'])\n",
    "    scores.setdefault('f1-score', []).append(report['1']['f1-score'])\n",
    "    scores.setdefault('accuracy', []).append(accuracy)\n",
    "    scores.setdefault('auc', []).append(auc)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This next function will help us visualize the distributions of our features, and give us an idea of what sort of transformations will be necessary."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_feature_distributions(df_: pd.DataFrame, f_columns):\n",
    "    fig, axes = plt.subplots(nrows=5, ncols=2, figsize=(15, 20))\n",
    "\n",
    "    axes = axes.flatten()\n",
    "\n",
    "    for i, col in enumerate(f_columns):\n",
    "        sns.histplot(df_[col], ax=axes[i], kde=True)\n",
    "        axes[i].set_title(f'Distribution of {col}')\n",
    "        axes[i].set_xlabel(col)\n",
    "        axes[i].set_ylabel('Count')\n",
    "    \n",
    "    for i in range(len(f_columns), len(axes)):\n",
    "        fig.delaxes(axes[i])\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`plot_performance_metrics` will do as the name implies -- plot our performance metrics for each model, such as accuracy, recall, precision, f1-score, etc. ."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "from matplotlib.ticker import MaxNLocator\n",
    "\n",
    "def plot_performance_metrics(model_scores: dict, num_folds: int, sampling: int = 0):\n",
    "    if len(list(model_scores.values())[0]['fold']) == 1:\n",
    "        # create a bar plot for each metric\n",
    "        label, scores = list(model_scores.items())[0]\n",
    "        df_scores = pd.DataFrame(scores).drop(columns=['fold'])\n",
    "        \n",
    "        fig, ax = plt.subplots(figsize=(10, 6))\n",
    "        df_scores.plot(kind='bar', ax=ax)\n",
    "        \n",
    "        ax.set_title(f'Metrics for {label}')\n",
    "        ax.set_xlabel('')\n",
    "        ax.set_ylabel('Score')\n",
    "        ax.legend(title='Metric')\n",
    "        ax.grid(True)\n",
    "\n",
    "        # Remove x-ticks and set y-ticks\n",
    "\n",
    "        ax.set_xticks([])\n",
    "        ax.yaxis.set_major_locator(MaxNLocator(11))\n",
    "        ax.set_yticks([i / 10.0 for i in range(11)])\n",
    "        \n",
    "        plt.tight_layout()\n",
    "\n",
    "    else:\n",
    "        fig, axes = plt.subplots(1, len(model_scores), figsize=(10,6), sharey=True)\n",
    "        for ax, (label, scores) in zip([axes], model_scores.items()):\n",
    "            sns.lineplot(data=pd.DataFrame(scores), x='fold', y='precision', label='Precision', marker='o', ax=ax)\n",
    "            sns.lineplot(data=pd.DataFrame(scores), x='fold', y='recall', label='Recall', marker='o', ax=ax)\n",
    "            sns.lineplot(data=pd.DataFrame(scores), x='fold', y='f1-score', label='F1-Score', marker='o', ax=ax)\n",
    "            sns.lineplot(data=pd.DataFrame(scores), x='fold', y='accuracy', label='Accuracy', marker='o', ax=ax)\n",
    "            sns.lineplot(data=pd.DataFrame(scores), x='fold', y='auc', label='AUC score', marker='o', ax=ax)\n",
    "            ax.set_title(f'Metrics Progression for {label}')\n",
    "            ax.set_xlabel('Fold')\n",
    "            ax.xaxis.set_major_locator(MaxNLocator(integer=True))\n",
    "            ax.set_ylabel('Score')\n",
    "            ax.legend()\n",
    "            ax.grid(True)\n",
    "    \n",
    "    if sampling > 0:\n",
    "        plot_title = f\"Model Performance Metrics over {num_folds} Folds (with over-sampling)\"\n",
    "    elif sampling < 0:\n",
    "        plot_title = f\"Model Performance Metrics over {num_folds} Folds (with under-sampling)\"\n",
    "    else:\n",
    "        plot_title = f\"Model Performance Metrics over {num_folds} Folds\"\n",
    "    plt.suptitle(plot_title, fontsize=16)\n",
    "    plt.tight_layout()\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Since we are working with a binary classification problem, a confusion matrix will serve as a very easy and intuitive way to visualize the models' performance.\n",
    "\n",
    "`plot_confusion_matrix` will give us exactly that."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_confusion_matrix(conf_matrix: dict, num_folds: int, sampling: int = 0):\n",
    "    fig, ax = plt.subplots(nrows=1, ncols=1)\n",
    "    # axList = axList.flatten()\n",
    "    fig.set_size_inches(10, 8)\n",
    "\n",
    "    ax.axis('off')\n",
    "\n",
    "    lab = next(iter(conf_matrix))\n",
    "\n",
    "    # for ax,lab in zip(axList[:-1], conf_matrices.keys()):\n",
    "    sns.heatmap(conf_matrix[lab], ax=ax, annot=True, fmt='d')\n",
    "    ax.set(title=lab)\n",
    "    \n",
    "    if sampling > 0:\n",
    "        plot_title = f\"Average Confusion Matrix Over {num_folds} Folds (with over-sampling)\"\n",
    "    elif sampling < 0:\n",
    "        plot_title = f\"Average Confusion Matrix Over {num_folds} Folds (with under-sampling)\"\n",
    "    else:\n",
    "        plot_title = f\"Average Confusion Matrix Over {num_folds} Folds\"\n",
    "    plt.suptitle(plot_title, fontsize=16)\n",
    "    plt.tight_layout()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can use the following functions to plot the coefficients of the logistic regression models we will be training."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_feature_coefs(coef, columns):\n",
    "    coef_dict = {}\n",
    "    for coef, feat in zip(coef, columns):\n",
    "        # if abs(coef) >= 0.01:\n",
    "        coef_dict[feat] = coef\n",
    "    # Sort coefficients\n",
    "    coef_dict = {k: v for k, v in sorted(coef_dict.items(), key=lambda item: item[1])}\n",
    "    return coef_dict\n",
    "\n",
    "def get_bar_colors(values):\n",
    "    color_vals = []\n",
    "    for val in values:\n",
    "        if val <= 0:\n",
    "            color_vals.append('r')\n",
    "        else:\n",
    "            color_vals.append('g')\n",
    "    return color_vals\n",
    "\n",
    "# Visualize coefficients\n",
    "def visualize_coefs(label: str, coef_dict: dict, num_folds: int, sampling: int):\n",
    "    features = list(coef_dict.keys())\n",
    "    values = list(coef_dict.values())\n",
    "    y_pos = np.arange(len(features))\n",
    "    color_vals = get_bar_colors(values)\n",
    "    plt.rcdefaults()\n",
    "    fig, ax = plt.subplots()\n",
    "    ax.barh(y_pos, values, align='center', color=color_vals)\n",
    "    ax.set_yticks(y_pos)\n",
    "    ax.set_yticklabels(features)\n",
    "    # labels read top-to-bottom\n",
    "    ax.invert_yaxis()  \n",
    "    ax.set_xlabel('Feature Coefficients')\n",
    "\n",
    "    if sampling > 0:\n",
    "        plot_title = f'Avg Coefficients for Model over {num_folds} folds : {label} (with over-sampling)'\n",
    "    elif sampling < 0:\n",
    "        plot_title = f'Avg Coefficients for Model over {num_folds} folds : {label} (with under-sampling)'\n",
    "    else:\n",
    "        plot_title = f'Avg Coefficients for Model over {num_folds} folds : {label}'\n",
    "    ax.set_title(plot_title)\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Loading and describing the dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First and foremost, let's load in our dataset. \n",
    "\n",
    "We will be using the [\"NASA | Nearest Earth Objects (1910-2024)\"](https://www.kaggle.com/datasets/ivansher/nasa-nearest-earth-objects-1910-2024) dataset from Kaggle. \n",
    "\n",
    "This dataset is a collection of 338,199 samples of near-earth objects (primarily asteroids) that have been tracked orbiting earth.\n",
    "\n",
    "It contains a total of 8 features, and a single binary label.\n",
    "\n",
    "Features:\n",
    "\n",
    "        - neo_id : Unique identifier for each asteroid\n",
    "\n",
    "        - name : Name of the object given by NASA\n",
    "\n",
    "        - absolute-magnitude : this represents the intrinsic luminosity of the object (lower value means a larger OR brighter object)\n",
    "\n",
    "        - estimated_diameter_min : the estimated minimum diameter of the object\n",
    "\n",
    "        - estimated_diameter_max : the estimated maximum diameter of the object\n",
    "\n",
    "        - orbiting_body : the primary body that the object is orbiting (Earth)\n",
    "\n",
    "        - relative_velocity : the velocity relative to earth in Kmph\n",
    "\n",
    "        - miss_distance : the distance in Km that the object missed earth in the logged pass\n",
    "\n",
    "\n",
    "Label:\n",
    "\n",
    "        - is_hazardous : boolean feature that shows whether the object is a risk to the orbiting body"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Notice that we drop any rows with null values.\n",
    "\n",
    "I felt this was safe to do, since our dataset is fairly large (300k+ samples), and this operation removed less than 1% of all the samples."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>neo_id</th>\n",
       "      <th>name</th>\n",
       "      <th>absolute_magnitude</th>\n",
       "      <th>estimated_diameter_min</th>\n",
       "      <th>estimated_diameter_max</th>\n",
       "      <th>orbiting_body</th>\n",
       "      <th>relative_velocity</th>\n",
       "      <th>miss_distance</th>\n",
       "      <th>is_hazardous</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2162117</td>\n",
       "      <td>162117 (1998 SD15)</td>\n",
       "      <td>19.14</td>\n",
       "      <td>0.394962</td>\n",
       "      <td>0.883161</td>\n",
       "      <td>Earth</td>\n",
       "      <td>71745.401048</td>\n",
       "      <td>5.814362e+07</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2349507</td>\n",
       "      <td>349507 (2008 QY)</td>\n",
       "      <td>18.50</td>\n",
       "      <td>0.530341</td>\n",
       "      <td>1.185878</td>\n",
       "      <td>Earth</td>\n",
       "      <td>109949.757148</td>\n",
       "      <td>5.580105e+07</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2455415</td>\n",
       "      <td>455415 (2003 GA)</td>\n",
       "      <td>21.45</td>\n",
       "      <td>0.136319</td>\n",
       "      <td>0.304818</td>\n",
       "      <td>Earth</td>\n",
       "      <td>24865.506798</td>\n",
       "      <td>6.720689e+07</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3132126</td>\n",
       "      <td>(2002 PB)</td>\n",
       "      <td>20.63</td>\n",
       "      <td>0.198863</td>\n",
       "      <td>0.444672</td>\n",
       "      <td>Earth</td>\n",
       "      <td>78890.076805</td>\n",
       "      <td>3.039644e+07</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>3557844</td>\n",
       "      <td>(2011 DW)</td>\n",
       "      <td>22.70</td>\n",
       "      <td>0.076658</td>\n",
       "      <td>0.171412</td>\n",
       "      <td>Earth</td>\n",
       "      <td>56036.519484</td>\n",
       "      <td>6.311863e+07</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    neo_id                name  absolute_magnitude  estimated_diameter_min  \\\n",
       "0  2162117  162117 (1998 SD15)               19.14                0.394962   \n",
       "1  2349507    349507 (2008 QY)               18.50                0.530341   \n",
       "2  2455415    455415 (2003 GA)               21.45                0.136319   \n",
       "3  3132126           (2002 PB)               20.63                0.198863   \n",
       "4  3557844           (2011 DW)               22.70                0.076658   \n",
       "\n",
       "   estimated_diameter_max orbiting_body  relative_velocity  miss_distance  \\\n",
       "0                0.883161         Earth       71745.401048   5.814362e+07   \n",
       "1                1.185878         Earth      109949.757148   5.580105e+07   \n",
       "2                0.304818         Earth       24865.506798   6.720689e+07   \n",
       "3                0.444672         Earth       78890.076805   3.039644e+07   \n",
       "4                0.171412         Earth       56036.519484   6.311863e+07   \n",
       "\n",
       "   is_hazardous  \n",
       "0         False  \n",
       "1          True  \n",
       "2         False  \n",
       "3         False  \n",
       "4         False  "
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv(\"nearest-earth-objects(1910-2024).csv\")\n",
    "df = df.dropna()\n",
    "df = df.reset_index(drop=True)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We will be ignoring the `neo_id`, `name`, and `orbiting_body` columns.\n",
    "\n",
    "The first two give us no predictive power, since they both are simply names given to the object.\n",
    "`orbiting_body` only has 1 unique value across the whole dataset, and so it will also give us no predictive power.\n",
    "\n",
    "We separate the features of interest for future use."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "feature_cols = df.columns[2:-1]\n",
    "feature_cols = feature_cols.drop('orbiting_body')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "feature dtypes:\n",
      " float64    5\n",
      "Name: count, dtype: int64\n",
      "\n",
      "label dtype:\n",
      " bool\n"
     ]
    }
   ],
   "source": [
    "print('feature dtypes:\\n',df[feature_cols].dtypes.value_counts())\n",
    "print('\\nlabel dtype:\\n', df['is_hazardous'].dtype)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's go ahead and recast the label from a boolean, and get an idea of how skewed the labels are."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "is_hazardous\n",
       "0    0.872366\n",
       "1    0.127634\n",
       "Name: proportion, dtype: float64"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.preprocessing import LabelEncoder\n",
    "\n",
    "le = LabelEncoder()\n",
    "df['is_hazardous'] = le.fit_transform(df.is_hazardous)\n",
    "df['is_hazardous'].value_counts(normalize=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The dataset is moderately skewed, only having about 13% of the labels being \"hazardous\" (the \"true\" label). \n",
    "\n",
    "We'll address this in the next section, where we perform our preprocessing of the data."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Preprocessing the data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Visualizing the distributions and correlations"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We'll begin this section by getting an idea of the basic statistics of the features."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df[feature_cols].describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We appear to have quite skewed distributions in our features, with the mean and max values differing by factors of over 100 in some cases. \n",
    "Additionally, we have some rather large values for `relative_velocity` and `miss_distance`. \n",
    "\n",
    "Since two of the models we will be training in this notebook are a logistic regression model and an SVM model, we will want to standardize our data and ensure normality.\n",
    "\n",
    "Let's take a look at the distributions of our features before we get into transforming our data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_feature_distributions(df, feature_cols)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As anticipated, our distributions are highly skewed. We will fix this in the next subsection.\n",
    "\n",
    "Next, let's check for any correlations among our features."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# sns.pairplot(df[feature_cols])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can already see some strong correlations between some of our features. \n",
    "\n",
    "Namely, we have an extremely high, positive correlation between `estimated_diameter_min` and `estimated_diameter_max`. This makes sense, as genuinely larger objects will likely have higher values for both of these features compared measurements of smaller objects.\n",
    "\n",
    "We also see negative correlations between `absolute_magnitude` and both `estimated_diameter_min` and `estimated_diameter_max`. This also makes sense, since (while as unintuitive as it may sound) a smaller value for `absolute_magnitude` (intrinsic luminosity) can refer to a larger object (or a more reflective object).\n",
    "\n",
    "Let's create a heatmap of the correlation values to get a clearer idea of the correlations."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_corr = df[feature_cols].corr()\n",
    "sns.heatmap(df_corr, annot=df_corr, fmt='0.2')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As expected, we have an essentially perfect positive correlation between `estimated_diameter_max` and `estimated_diameter_min`, \n",
    "as well as a strong negative correlation between each of those features and `absolute_magnitude`.\n",
    "\n",
    "These correlations may be problematic for our training,  but we'll simply take note of this for now, and address it later as we analyze the performance of the models.\n",
    "\n",
    "Let's get into scaling."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Transforming the features"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To address the highly skewed distributions of our features, I had to employ a variety of transformations. Simple standard scaling was either ineffective or not enough to normalize all of the features.\n",
    "\n",
    "I kept to monotonic transformations, since many of our features are ordinal in nature.\n",
    "\n",
    "I apply a min-max scaler after achieving normal distributions, since these features don't make much sense if they're negative. This should allow for much more interpretable results."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.preprocessing import PowerTransformer\n",
    "from sklearn.preprocessing import QuantileTransformer\n",
    "\n",
    "\n",
    "dfc = df.copy()  # copy our dataframe, so we can apply transformations on the copy rather than the original.\n",
    "\n",
    "mms = MinMaxScaler()\n",
    "ss = StandardScaler()\n",
    "bct = PowerTransformer(method='box-cox')\n",
    "qt = QuantileTransformer(output_distribution='normal', random_state=42)\n",
    "\n",
    "dfc['absolute_magnitude'] = ss.fit_transform(pd.DataFrame(dfc['absolute_magnitude']))\n",
    "\n",
    "dfc['estimated_diameter_min'] = bct.fit_transform(pd.DataFrame(dfc['estimated_diameter_min']))\n",
    "\n",
    "dfc['estimated_diameter_max'] = bct.fit_transform(pd.DataFrame(dfc['estimated_diameter_max']))\n",
    "\n",
    "dfc['relative_velocity'] = bct.fit_transform(pd.DataFrame(dfc['relative_velocity']))\n",
    "dfc['relative_velocity'] = ss.fit_transform(pd.DataFrame(dfc['relative_velocity']))\n",
    "\n",
    "dfc['miss_distance'] = qt.fit_transform(pd.DataFrame(dfc['miss_distance']))\n",
    "\n",
    "if True: # this enables us to toggle min-max scaling\n",
    "    dfc['absolute_magnitude'] = mms.fit_transform(pd.DataFrame(dfc['absolute_magnitude']))\n",
    "    dfc['estimated_diameter_min'] = mms.fit_transform(pd.DataFrame(dfc['estimated_diameter_min']))\n",
    "    dfc['estimated_diameter_max'] = mms.fit_transform(pd.DataFrame(dfc['estimated_diameter_max']))\n",
    "    dfc['relative_velocity'] = mms.fit_transform(pd.DataFrame(dfc['relative_velocity']))\n",
    "    dfc['miss_distance'] = mms.fit_transform(pd.DataFrame(dfc['miss_distance']))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's check how well we managed to reshape our distributions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_feature_distributions(dfc, feature_cols)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It looks like we managed to make all of our features fairly normally distributed, and their scale is now consistent.\n",
    "\n",
    "Both of these properties will be valuable for our first two model types."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dfc[feature_cols].describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model Training"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we get into building and training our models.\n",
    "\n",
    "First, we will build three logistic regression models, and compare their performance. We will build a standard logistic regression model (no regularization), as well as two other models with L1 and L2 regularization.\n",
    "\n",
    "From there, we will train two SVM models. One will be a linear SVC model, while the second will include a polynomial kernel.\n",
    "\n",
    "Lastly, we will construct a Random Forest classifier.\n",
    "\n",
    "Once all these models are trained, and the best of each model type are identified, we will compare the performance of the remaining three and collect some insights."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Our train-test loop"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Below is the function we will use to train our models throughout this notebook.\n",
    "\n",
    "We will employ a stratified K-fold approach, and allow for over-sampling through SMOTE, as well as undersampling using a `RandomUnderSampler`. These sampling techniques will only be enabled if indicated in the function.\n",
    "\n",
    "This function will return the performance metrics, so we can pass them in to plot the metrics across folds, as well as the average confusion matrix for each model passed."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "from imblearn.over_sampling import SMOTE\n",
    "from imblearn.under_sampling import RandomUnderSampler\n",
    "from sklearn.metrics import classification_report, accuracy_score, roc_auc_score\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.model_selection import StratifiedShuffleSplit\n",
    "\n",
    "\n",
    "def train_test_results(\n",
    "        df_: pd.DataFrame, num_folds: int, test_size: float,\n",
    "        model, label: str,\n",
    "        sampling: int = 0,\n",
    "        **kwargs):\n",
    "    model_scores = {}\n",
    "    conf_matrix = {}\n",
    "    avg_coefs = []\n",
    "    coefs = { 'label': label, 'coefficients': None }\n",
    "\n",
    "    sss = StratifiedShuffleSplit(n_splits=num_folds, test_size=test_size, random_state=42)\n",
    "\n",
    "    for fold, (train_idx, test_idx) in enumerate( sss.split(df_[feature_cols], df_.is_hazardous) ):\n",
    "        estimator = model(**kwargs)\n",
    "\n",
    "        # create train and test splits for each fold\n",
    "        X_train = df_.loc[train_idx, feature_cols]\n",
    "        y_train = df_.loc[train_idx, 'is_hazardous']\n",
    "        X_test  = df_.loc[test_idx, feature_cols]\n",
    "        y_test  = df_.loc[test_idx, 'is_hazardous']\n",
    "\n",
    "        # perform under-/over-sampling if indicated\n",
    "        if sampling < 0:\n",
    "            rus = RandomUnderSampler(random_state=42)\n",
    "            X_train, y_train = rus.fit_resample(X_train, y_train)\n",
    "        elif sampling > 0:\n",
    "            smote = SMOTE(random_state=42)\n",
    "            X_train, y_train = smote.fit_resample(X_train, y_train)\n",
    "        \n",
    "        # fit the models\n",
    "        estimator.fit(X_train, y_train)\n",
    "\n",
    "        # if GridSearchCV is passed, we take the best estimator\n",
    "        if hasattr(estimator, 'best_estimator_'):\n",
    "            print(\"best params\", estimator.best_params_)\n",
    "            estimator = estimator.best_estimator_\n",
    "        # gather predictions on test set\n",
    "        preds = estimator.predict(X_test) \n",
    "        # create report of metrics\n",
    "        model_report = classification_report(y_test, preds, output_dict=True)\n",
    "        accuracy = accuracy_score(y_test, preds)\n",
    "        auc = roc_auc_score(y_test, preds)\n",
    "        # add metrics for the fold to the scores dict\n",
    "        allocate_report_metrics(fold+1, model_scores.setdefault(label, {}), model_report, accuracy, auc)\n",
    "        # add confusion matrix values for the fold\n",
    "        conf_matrix.setdefault(label, []).append(confusion_matrix(y_test, preds))\n",
    "        \n",
    "        if hasattr(estimator, 'coef_'):\n",
    "            avg_coefs.append(estimator.coef_) \n",
    "    \n",
    "    # average our confusion matrices gathered across each fold\n",
    "    for label, mat_list in conf_matrix.items():\n",
    "        conf_matrix[label] = np.mean(np.asarray(mat_list), axis=0).round().astype(int)\n",
    "\n",
    "    # average our coefficients across each fold (for interpretation)\n",
    "    if avg_coefs != []:\n",
    "        avg_coefs = np.mean(np.asarray(avg_coefs), axis=0)[0]\n",
    "        coefs['coefficients'] = get_feature_coefs(avg_coefs, df_[feature_cols].columns)\n",
    "\n",
    "    return model_scores, conf_matrix, coefs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Logistic Regression Models"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We will be building 3 different logistic regression models to compare and interpret from. One basic logistic regression model (with no regularization), and two models *with* regularization, one with L1 regularization and one with L2 regularization.\n",
    "\n",
    "The solver we will be using is `saga`, since, while not very high-dimensional, the dataset is rather large, and `saga` may more easily converge than some of the other solvers.\n",
    "\n",
    "Due to the class imbalance, we will introduce 'balanced' class weights, in order to more completely represent the minority class."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Simple Logistic Regression"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Training and Test Results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "model_label = 'lr'\n",
    "\n",
    "lr_kwargs = {\n",
    "    'solver': 'saga',\n",
    "    'max_iter': 1000, \n",
    "    'n_jobs': -1, \n",
    "    'class_weight': 'balanced'}\n",
    "\n",
    "num_folds = 5\n",
    "\n",
    "for sampling in range(-1, 2):\n",
    "    lr_scores, lr_conf_mat, lr_coef = train_test_results(\n",
    "                                            df_=dfc,\n",
    "                                            num_folds=num_folds,\n",
    "                                            test_size=0.3,\n",
    "                                            model=LogisticRegression,\n",
    "                                            label=model_label,\n",
    "                                            sampling=sampling,\n",
    "                                            **lr_kwargs)\n",
    "    \n",
    "    plot_performance_metrics(lr_scores, num_folds=num_folds, sampling=sampling)\n",
    "    plot_confusion_matrix(lr_conf_mat, num_folds=num_folds, sampling=sampling)\n",
    "    visualize_coefs(lr_coef['label'], lr_coef['coefficients'], num_folds=num_folds, sampling=sampling)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Discussion"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Our plots for the metrics across folds are relatively flat for all metrics, indicating that our model is performing pretty consistently with the data.\n",
    "\n",
    "Additionally, the performance metrics show very little change with the different sampling techniques. It's likely that relying on `'balanced'` class weights is sufficient. We will omit the sampling methods for the remainder of the logistic regression model training, since we should expect a similar lack of change between the sampling techniques.\n",
    "\n",
    "We see from both the metrics plot and the confusion matrix that the model is quite good at predicting true negative outcomes, and its recall is rather high. While the precision and f1-score are rather low, having a high recall is desirable for this sort of problem, as we would rather err on the side of caution when it comes to detecting hazardous objects in space.\n",
    "\n",
    "Looking at our coefficients across the different sampling methods, we see a lot of variation. \n",
    "\n",
    "Under-sampling yielded the most intuitive coefficients. The signs for each align with what we would expect for this kind of problem.\n",
    "\n",
    "With neither under- nor over-sampling, we can see the coefficients have inflated a bit, but also something a bit problematic. \n",
    "The coefficients for `estimated_diameter_min` and `estimated_diameter_max` are negative. \n",
    "This appears contradictory to what we might expect, since the large, negative coefficient for `absolute_magnitude` indicates that a larger object means it is more likely to be hazardous, but the negative coefficents for `estimated_diameter_min` and `estimated_diameter_max` indicate the opposite.\n",
    "\n",
    "The coefficients with over-sampling appear similar to those of the prior test without any additional sampling techniques, though they have inflated even further."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Logistic Regression with L1 Regularization"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Given the consistency of our metrics across our 5 folds for the simple logistic regression model, we will continue with a single train-test split for the remainder of our logistic regression model training. The decision to do this is primarily to speed up the training process, as we will be introducing GridSearchCV in order to determine the best regularization strength."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Training and Test Results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "\n",
    "model_label = 'lr_L1'\n",
    "\n",
    "lrl1 = LogisticRegression(\n",
    "    penalty='l1', solver='saga', \n",
    "    class_weight='balanced', \n",
    "    random_state=42, max_iter=1000, n_jobs=-1)\n",
    "\n",
    "lrl1_param_grid = { 'C': np.geomspace(start=1e-4, stop=1e4, num=9) }\n",
    "\n",
    "lrl1_kwargs = {\n",
    "    'estimator': lrl1, 'param_grid': lrl1_param_grid, \n",
    "    'scoring': 'f1', 'n_jobs': -1}\n",
    "\n",
    "sampling = 0\n",
    "num_folds = 1  # remove additional folds\n",
    "\n",
    "lrl1_scores, lrl1_conf_mat, lrl1_coef = train_test_results(\n",
    "                                        df_=dfc,\n",
    "                                        num_folds=num_folds,\n",
    "                                        test_size=0.3,\n",
    "                                        model=GridSearchCV,\n",
    "                                        label=model_label,\n",
    "                                        sampling=sampling,\n",
    "                                        **lrl1_kwargs)\n",
    "\n",
    "plot_performance_metrics(lrl1_scores, num_folds=num_folds, sampling=sampling)\n",
    "plot_confusion_matrix(lrl1_conf_mat, num_folds=num_folds, sampling=sampling)\n",
    "visualize_coefs(lrl1_coef['label'], lrl1_coef['coefficients'], num_folds=num_folds, sampling=sampling)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Discussion"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We're seeing a marginal increase in the performance metrics with this L1-regularized model compared to the previous simple logistic regression model. Interestingly, our feature coefficients appear to have inflated tremendously. This could be due to the larger training set, and hint at over-fitting.\n",
    "\n",
    "Let's try manually increasing the regularization strength, and see if we can get comparable results with more intuitive coefficients.\n",
    "\n",
    "After manually testing various powers of 10, the feature coefficients remained similarly large and negative until `C=0.01`, and all but one feature vanished entirely around `C=0.001`. So let's try testing some `C` values between those."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_label = 'lr_strongerL1'\n",
    "\n",
    "lrl1 = LogisticRegression(\n",
    "    penalty='l1', solver='saga', \n",
    "    class_weight='balanced', \n",
    "    random_state=42, max_iter=1000, n_jobs=-1)\n",
    "\n",
    "# limit the bounds of `C` values\n",
    "#   this will manually increase our regularization strength\n",
    "lrl1_param_grid = { 'C': np.geomspace(start=1e-3, stop=1e-2, num=9) }\n",
    "                   \n",
    "lrl1_kwargs = {\n",
    "    'estimator': lrl1, 'param_grid': lrl1_param_grid, \n",
    "    'scoring': 'f1', 'n_jobs': -1}\n",
    "\n",
    "sampling = 0\n",
    "num_folds = 1  # remove additional folds\n",
    "\n",
    "lrl1_scores, lrl1_conf_mat, lrl1_coef = train_test_results(\n",
    "                                        df_=dfc,\n",
    "                                        num_folds=num_folds,\n",
    "                                        test_size=0.3,\n",
    "                                        model=GridSearchCV,\n",
    "                                        label=model_label,\n",
    "                                        sampling=sampling,\n",
    "                                        **lrl1_kwargs)\n",
    "\n",
    "plot_performance_metrics(lrl1_scores, num_folds=num_folds, sampling=sampling)\n",
    "plot_confusion_matrix(lrl1_conf_mat, num_folds=num_folds, sampling=sampling)\n",
    "visualize_coefs(lrl1_coef['label'], lrl1_coef['coefficients'], num_folds=num_folds, sampling=sampling)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "While we took a slight hit in performance, it remained fairly comparable to the previous test, and our coefficients make a bit more sense. \n",
    "\n",
    "It would make sense that a lower `miss_distance` would correspond to the object being more hazardous, and similarly for a larger object (indicated by *lower* `absolute_magnitude`). An object with a higher `relative_velocity` being deemed as more dangerous also makes sense within our problem.\n",
    "\n",
    "Strangely, however, contributions from the estimated diameter features have vanished entirely.\n",
    "\n",
    "The run time was significantly shorter with higher regularization as well, only taking about 28 seconds, while the previous L1-regularized model took about 8.75 minutes.\n",
    "\n",
    "Let's evaluate our last logistic regression model, and then we'll compare and interpret the results for all of them."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Logistic Regression with L2 Regularization"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Given the results from the L1 regularization tests, let's see how a logistic regression model with L2 regularization behaves with similar hyperparameters."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Training and Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_label = 'lr_L2'\n",
    "\n",
    "lrl2 = LogisticRegression(\n",
    "    penalty='l2', solver='saga', \n",
    "    class_weight='balanced', \n",
    "    random_state=42, max_iter=1000, n_jobs=-1)\n",
    "\n",
    "lrl2_param_grid = { 'C': np.geomspace(start=1e-4, stop=1e4, num=9) }\n",
    "\n",
    "lrl2_kwargs = {\n",
    "    'estimator': lrl2, 'param_grid': lrl2_param_grid, \n",
    "    'scoring': 'f1', 'n_jobs': -1}\n",
    "\n",
    "sampling = 0\n",
    "num_folds = 1  # remove additional folds\n",
    "\n",
    "lrl2_scores, lrl2_conf_mat, lrl2_coef = train_test_results(\n",
    "                                        df_=dfc,\n",
    "                                        num_folds=num_folds,\n",
    "                                        test_size=0.3,\n",
    "                                        model=GridSearchCV,\n",
    "                                        label=model_label,\n",
    "                                        sampling=sampling,\n",
    "                                        **lrl2_kwargs)\n",
    "\n",
    "plot_performance_metrics(lrl2_scores, num_folds=num_folds, sampling=sampling)\n",
    "plot_confusion_matrix(lrl2_conf_mat, num_folds=num_folds, sampling=sampling)\n",
    "visualize_coefs(lrl2_coef['label'], lrl2_coef['coefficients'], num_folds=num_folds, sampling=sampling)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Discussion"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Once again, we see a small increase in performance metrics compared to the simple logistic regression model, but our coefficients hint at overfitting.\n",
    "\n",
    "Let's proceed with a similar manual increase in the regularization strength as before and compare the differences.\n",
    "\n",
    "As I decreased the upper bound of the range of `C` values, the largest `C` (lowest regularization strength) was consistently selected. This behavior stopped after setting the upper bound to 1.0, deciding `C=0.01` yielded the best results. Let's perform a more fine-grained parameter search around this value."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_label = 'lr_strongerL2'\n",
    "\n",
    "lrl2 = LogisticRegression(\n",
    "    penalty='l2', solver='saga', \n",
    "    class_weight='balanced', \n",
    "    random_state=42, max_iter=1000, n_jobs=-1)\n",
    "\n",
    "lrl2_param_grid = { 'C': np.geomspace(start=1e-3, stop=1e-1, num=5) }\n",
    "\n",
    "lrl2_kwargs = {\n",
    "    'estimator': lrl2, 'param_grid': lrl2_param_grid, \n",
    "    'scoring': 'f1', 'n_jobs': -1}\n",
    "\n",
    "sampling = 0\n",
    "num_folds = 1  # remove additional folds\n",
    "\n",
    "lrl2_scores, lrl2_conf_mat, lrl2_coef = train_test_results(\n",
    "                                        df_=dfc,\n",
    "                                        num_folds=num_folds,\n",
    "                                        test_size=0.3,\n",
    "                                        model=GridSearchCV,\n",
    "                                        label=model_label,\n",
    "                                        sampling=sampling,\n",
    "                                        **lrl2_kwargs)\n",
    "\n",
    "plot_performance_metrics(lrl2_scores, num_folds=num_folds, sampling=sampling)\n",
    "plot_confusion_matrix(lrl2_conf_mat, num_folds=num_folds, sampling=sampling)\n",
    "visualize_coefs(lrl2_coef['label'], lrl2_coef['coefficients'], num_folds=num_folds, sampling=sampling)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We see that our performance metrics remain similar to those of previous tests, but our coefficients make much more intuitive sense.\n",
    "\n",
    "The coefficients for `absolute_magnitude`, `estimated_diameter_max`, `estimated_diameter_min`, and `relative_velocity` indicate that the larger and faster an object is, the more likely it is to be hazardous. As explained before, `miss_distance` having a negative coefficient also makes sense, since the closer the object is while passing earth, the more likely it is to be hazardous. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Conclusions from Logistic Regression Tests"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "These models appear to be decently good at predicting true negative cases, which may be expected since our dataset is heavily skewed in favor of the negative cases. \n",
    "\n",
    "While our f1-score is pretty low, our recall is fairly high, which is reassuring for this problem since we would rather err on the side of caution than mistakenly think an object is not hazardous.\n",
    "\n",
    "Overall, these models' predicitve capabilities aren't exactly impressive, but we were able to get at least one with some interpretable results without sacrificing significant performance.\n",
    "\n",
    "Given the largely unintuitive coefficients from some of our tests, it may warrant some additional investigation into our dataset.\n",
    "\n",
    "Our L2-regularized model with stronger regularization had the fastest run time, maintained performance well, and had the most sensible coefficients. For these reasons, we will compare the SVM and random forest models with this logistic regression model moving forward."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### SVM Classifiers"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here, we will be training two SVM classfier models.\n",
    "\n",
    "Our first model will be a linear SVC model.\n",
    "\n",
    "Our second will be an SVC with a polynomial kernel.\n",
    "\n",
    "We will compare the performance of the two, and select the best to ultimately compare with the other model types trained in this notebook."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Linear SVM Classifier"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "From some prior testing, I determined that the better penalty to use was `l2`. It converged much faster, as tests using the `l1` penalty failed to converge with even 100,000 iterations, and had runtimes of over 30 minutes.\n",
    "\n",
    "We'll keep the `'balanced'` class weights, and determine the best regularization strength using `GridSearchCV`. I narrowed the range of values based off the prior testing.\n",
    "\n",
    "We will also test the performance across 5 folds again, as well as our different sampling techniques."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Training and Results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.svm import LinearSVC\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "model_label = 'linear_svc'\n",
    "\n",
    "svc_lin = LinearSVC(penalty='l2', class_weight='balanced', random_state=42, max_iter=10000)\n",
    "\n",
    "svc_lin_param_grid = {\n",
    "    'C': np.geomspace(1e-5, 1e-3, num=10),\n",
    "}\n",
    "\n",
    "svc_lin_kwargs = {\n",
    "    'estimator': svc_lin, 'param_grid': svc_lin_param_grid, \n",
    "    'scoring': 'f1', 'n_jobs': -1}\n",
    "\n",
    "num_folds = 5\n",
    "# sampling = 0\n",
    "for sampling in range(-1, 2):\n",
    "    svc_lin_scores, svc_lin_conf_mat, _ = train_test_results(\n",
    "                                            df_=dfc,\n",
    "                                            num_folds=num_folds,\n",
    "                                            test_size=0.3,\n",
    "                                            model=GridSearchCV,\n",
    "                                            label=model_label,\n",
    "                                            sampling=sampling,\n",
    "                                            **svc_lin_kwargs)\n",
    "\n",
    "    plot_performance_metrics(svc_lin_scores, num_folds=num_folds, sampling=sampling)\n",
    "    plot_confusion_matrix(svc_lin_conf_mat, num_folds=num_folds, sampling=sampling)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Discussion"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Once again, we see very high consistency across folds, so we will limit the number of folds for the next SVM model. \n",
    "\n",
    "We do see a noticeable performance increase compared to our logistic regression model. We have a nominally higher recall, though our precision is similarly poor (if not a little worse). As a result, our f1-score remains low.\n",
    "\n",
    "We're seeing a substantial decrease in the number of false-negative predictions, which is somewhat reassuring, though we are getting a higher proportion of false-positive predictions as well.\n",
    "\n",
    "The differences in performance between sampling techniques are interesting here, as we see improvements in our performance metrics compared to the case with no additional sampling beyond our stratefied k-fold strategy. Despite this, we will proceed with the next SVM model without our additional sampling techniques, so as to get as much information from the dataset as possible."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Non-linear SVM"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As mentioned before, we will train this model on a single fold of the dataset, since we maintained consistent performance metrics across the 5 folds in our linear SVM tests. Additionally, we will be omitting the additional sampling techniques.\n",
    "\n",
    "From some prior testing, the `'poly'` kernel appeared to perform the best compared to `'rbf'` and `'sigmoid'`.\n",
    "\n",
    "Like we did with the regularized logistic regression models, we will use `GridSearchCV` to identify the ideal regularization strength. Within those prior tests, a `C` value of 0.1 was deemed optimal, but we will test other strengths around that value here as well."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Training and Results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.svm import SVC\n",
    "\n",
    "model_label = 'svc_poly'\n",
    "\n",
    "svc_poly = SVC(C=0.1, kernel='poly', class_weight='balanced', max_iter=-1)\n",
    "\n",
    "svc_poly_param_grid = {\n",
    "    'C': np.geomspace(1e-2, 1e0, num=5)}\n",
    "\n",
    "svc_poly_kwargs = {\n",
    "    'estimator': svc_poly, 'param_grid': svc_poly_param_grid, \n",
    "    'scoring': 'f1', 'n_jobs': -1}\n",
    "\n",
    "num_folds = 1\n",
    "sampling = 0\n",
    "svc_poly_scores, svc_poly_conf_mat, _ = train_test_results(\n",
    "                                            df_=dfc,\n",
    "                                            num_folds=num_folds,\n",
    "                                            test_size=0.3,\n",
    "                                            model=GridSearchCV,\n",
    "                                            label=model_label,\n",
    "                                            sampling=sampling,\n",
    "                                            **svc_poly_kwargs)\n",
    "\n",
    "plot_performance_metrics(svc_poly_scores, num_folds=num_folds, sampling=sampling)\n",
    "plot_confusion_matrix(svc_poly_conf_mat, num_folds=num_folds, sampling=sampling)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Discussion"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The first thing we notice is that this model has a much higher recall. \n",
    "\n",
    "Our other metrics, however, remain relatively unchanged, so it's hard to say the 44.5 minute run time is justified.\n",
    "\n",
    "For this reason, we will continue on with our comparisons between model types using the linear SVC model."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### SVM Classifier Conclusions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lrl2_scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"linear_svc:\")\n",
    "for key, val in svc_lin_scores['linear_svc'].items():\n",
    "    if key == 'fold':\n",
    "        continue\n",
    "    print(key, np.mean(val))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The performance of our SVM classifier models showed very little improvement in most metrics from our L2-regularized logistic regression model. \n",
    "\n",
    "The most notable improvement over our L2-regularized logistic regression model is the much higher recall.\n",
    "\n",
    "For the other metrics, we see we had slightly lower precision, but a slightly higher AUC score.\n",
    "\n",
    "As for run time, our chosen logistic regression model finished its train-test loop in ~16 seconds, while the linear SVC model completes a similar run in ~5 seconds (this time was determined by running the linear SVC model in a separate train-test loop with a single C value, 1 fold, and no additional sampling methods).\n",
    "\n",
    "Overall, I think with having a much higher recall, comparable other metrics, and a much lower runtime, I think the linear SVC model wins this round."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Random Forest Classifier"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Lastly, we will be training a single Random Forest classifier model.\n",
    "\n",
    "We will be using the Gini index as our criterion, and we will be including the `'balanced'` class weights again.\n",
    "\n",
    "For our `max_features` and `n_estimators` parameters, we will use `GridSearchCV` to determine the best combination within the following ranges:\n",
    "    \n",
    "        - max_features: [2, 3, 4]\n",
    "    \n",
    "        - n_estimators: [100, 250, 500]\n",
    "\n",
    "Since random forest doesn't demand standardized/scaled features, we will also run the model with the winning parameters on the un-scaled data to see if there are any noticeable performance differences."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Training and Results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "model_label = 'rand_forest'\n",
    "\n",
    "rand_forest = RandomForestClassifier(\n",
    "    n_estimators=500, criterion='gini', max_features='sqrt', \n",
    "    n_jobs=-1, random_state=42, class_weight='balanced')\n",
    "\n",
    "rand_forest_param_grid = {\n",
    "    'max_features': [2, 3, 4],\n",
    "    'n_estimators': [100, 250, 500]}\n",
    "\n",
    "rand_forest_kwargs = {\n",
    "    'estimator': rand_forest, 'param_grid': rand_forest_param_grid, \n",
    "    'scoring': 'f1', 'n_jobs': -1}\n",
    "\n",
    "num_folds = 1\n",
    "sampling = 0\n",
    "rand_forest_scores, rand_forest_conf_mat, _ = train_test_results(\n",
    "                                                df_=dfc,\n",
    "                                                num_folds=num_folds,\n",
    "                                                test_size=0.3,\n",
    "                                                model=GridSearchCV,\n",
    "                                                label=model_label,\n",
    "                                                sampling=sampling,\n",
    "                                                **rand_forest_kwargs)\n",
    "\n",
    "plot_performance_metrics(rand_forest_scores, num_folds=num_folds, sampling=sampling)\n",
    "plot_confusion_matrix(rand_forest_conf_mat, num_folds=num_folds, sampling=sampling)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It looks like 2 `max_features` and 500 `n_estimators` are our winning parameters.\n",
    "\n",
    "Let's do our second run with the other sampling techniques included for a deeper comparison. Then we'll move onto discussion."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "model_label = 'rand_forest'\n",
    "\n",
    "rand_forest = RandomForestClassifier(\n",
    "    n_estimators=100, criterion='gini', max_features='sqrt', \n",
    "    n_jobs=-1, random_state=42, class_weight='balanced')\n",
    "\n",
    "rand_forest_param_grid = {\n",
    "    'max_features': [2],\n",
    "    'n_estimators': [500]}\n",
    "\n",
    "rand_forest_kwargs = {\n",
    "    'estimator': rand_forest, 'param_grid': rand_forest_param_grid, \n",
    "    'scoring': 'f1', 'n_jobs': -1}\n",
    "\n",
    "num_folds = 1\n",
    "# sampling = 0\n",
    "for sampling in [-1, 1, 0]:\n",
    "    rand_forest_scores, rand_forest_conf_mat, _ = train_test_results(\n",
    "                                                    df_=df,  # run using the original dataset, rather than the transformed copy\n",
    "                                                    num_folds=num_folds,\n",
    "                                                    test_size=0.3,\n",
    "                                                    model=GridSearchCV,\n",
    "                                                    label=model_label,\n",
    "                                                    sampling=sampling,\n",
    "                                                    **rand_forest_kwargs)\n",
    "\n",
    "    plot_performance_metrics(rand_forest_scores, num_folds=num_folds, sampling=sampling)\n",
    "    plot_confusion_matrix(rand_forest_conf_mat, num_folds=num_folds, sampling=sampling)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Discussion"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Summary and Conclusions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Describing the Data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The dataset used in this notebook is the [\"NASA | Nearest Earth Objects (1910-2024)\"](https://www.kaggle.com/datasets/ivansher/nasa-nearest-earth-objects-1910-2024) dataset from Kaggle. This dataset contains a collection of 338,199 samples of \"near earth objects\" (asteroids), which are classified as either \"hazardous\" or \"not hazardous\".\n",
    "\n",
    "Each sample has 8 features:\n",
    "\n",
    "        - neo_id : Unique identifier for each asteroid\n",
    "\n",
    "        - name : Name of the object given by NASA\n",
    "\n",
    "        - absolute-magnitude : this represents the intrinsic luminosity of the object (lower value means a larger OR brighter object)\n",
    "\n",
    "        - estimated_diameter_min : the estimated minimum diameter of the object\n",
    "\n",
    "        - estimated_diameter_max : the estimated maximum diameter of the object\n",
    "\n",
    "        - orbiting_body : the primary body that the object is orbiting (Earth)\n",
    "\n",
    "        - relative_velocity : the velocity relative to earth in Kmph\n",
    "\n",
    "        - miss_distance : the distance in Km that the object missed earth in the logged pass\n",
    "\n",
    "`neo_id`, `name`, and `orbiting_body` are excluded from the training, since the first two are simply names given to each object, and `orbiting_body` only has a single unique value across all samples. For these reasons, these features offer no predictive power.\n",
    "\n",
    "In addition to dropping these columns, there are a small amount ( < 1%) of samples that contain null values. Since the number of these samples is very small, I felt it was safe to remove these from our data.\n",
    "\n",
    "The distributions for our features are all highly skewed, and vary greatly in scale. Additionally, the features show strong correlations. `estimated_diameter_min` and `estimated_diameter_max` have a near perfect positive correlation. `estimated_diameter_min` and `estimated_diameter_max` also both had a very strong negative correlation with `absolute_magnitude`. These correlations make sense, since the larger an object is, both the `estimated_diameter_min` and `estimated_diameter_max` should be larger, and `absolute_magnitude` should be smaller, since a smaller `absolute_magnitude` corresponds to a larger (or brighter) object.\n",
    "\n",
    "To address the skewed distributions of our features, I applied necessary transformations to normalize each feature's distribution, as well as fix the scale with a min-max scaler. The gaussian-like distributions are preferrable for the first two models we trained (logistic regression and SVM), and the choice of using the min-max scaler after normalization was to keep the values positive for interpretability (negative distances and sizes make little sense for this problem)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Objective of Analysis"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this notebook, we trained and evaluated several different models: 3 logistic regression classifiers, 2 SVM classifiers, and a random forest classifier.\n",
    "\n",
    "Since we trained multiple logistic regression and SVM classifiers, we identified which performs the best to compare with the other model types.\n",
    "\n",
    "Our goal is to identify which model type performs best on the dataset in terms of run time and f1-score."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model Results and Comparisons"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Logistic Regression Models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lr_scores\n",
    "print('simple logistic regression:')\n",
    "for key, val in lr_scores['lr'].items():\n",
    "    if key == 'fold':\n",
    "        continue\n",
    "    print('\\t', key, np.mean(val))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lrl1_scores\n",
    "print('L1-regularized logistic regression:')\n",
    "for key, val in lrl1_scores['lr_strongerL1'].items():\n",
    "    if key == 'fold':\n",
    "        continue\n",
    "    print('\\t', key, np.mean(val))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lrl2_scores\n",
    "print('L2-regularized logistic regression:')\n",
    "for key, val in lrl2_scores['lr_strongerL2'].items():\n",
    "    if key == 'fold':\n",
    "        continue\n",
    "    print('\\t', key, np.mean(val))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We trained three different logistic regression models in order to find out which performed the best in terms of our desired metric and run time.\n",
    "\n",
    "Overall, our logistic regression models performed rather poorly. While they were able to achieve decently high recall, our f1-score was hindered by the poor precision score.\n",
    "\n",
    "When trained and tested across 5 stratefied folds, the performance was very stable.\n",
    "\n",
    "Our L2-regularized model performed the fastest at around 15 seconds, and was able to produce much more intuitive and stable coefficients compared to the other two logistic regression models. And though it was marginal, it did yield the highest f1-score."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### SVM Models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "svc_lin_scores\n",
    "print('Linear SVC:')\n",
    "for key, val in svc_lin_scores['linear_svc'].items():\n",
    "    if key == 'fold':\n",
    "        continue\n",
    "    print('\\t', key, np.mean(val))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "svc_poly_scores\n",
    "print('SVC with Polynomial Kernel:')\n",
    "for key, val in svc_poly_scores['svc_poly'].items():\n",
    "    if key == 'fold':\n",
    "        continue\n",
    "    print('\\t', key, np.mean(val))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We trained two SVM classifier models. The first was a linear SVC, and the second was an SVC with a polynomial kernel.\n",
    "\n",
    "The two models performed very similarly, with the polynomial SVC only beating the linear SVC in the f1-score by 0.01. However, the run time difference was substantial. The linear SVC model finished the train-test loop in about 1.25 minutes, whereas the polynomial SVC model finished in 44.75 minutes. \n",
    "\n",
    "Given the very minute performance difference, I determined the linear SVC model was much more suited for this problem."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Random Forest Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rand_forest_scores\n",
    "print('Random Forest:')\n",
    "for key, val in rand_forest_scores['rand_forest'].items():\n",
    "    if key == 'fold':\n",
    "        continue\n",
    "    print('\\t', key, np.mean(val))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The random forest model performed much more evenly across its metrics.\n",
    "\n",
    "With the highest accuracy and f1-score so far, it showed some good promise. However, the poor recall is worrisome, as low recall for determining a hazardous asteroids is problematic.\n",
    "\n",
    "The auc score was also not as good as either the linear SVC model, nor the L2-regularized logistic regression model. While not our metric of focus for these experiments, it's worth noting.\n",
    "\n",
    "Lastly, the run time for the random forest model was just under 6 minutes. While this may be reducible somewhat by limiting the number of estimators, we should expect to see a drop in performance from this."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Best Model Based on Results"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As per our objective, we were trying to identify the model best suited to the problem in terms of f1-score and runtime. \n",
    "\n",
    "Of the 6 models tested, it seems the linear SVC model may be best suited for this problem. While it had a lower f1-score than the random forest model (0.46 for linear SVC, 0.62 for random forest), its run time was significantly faster (~5sec for linear SVC, 5min50sec for random forest). With some further experiments varying the transformations applied to the features, I'm sure a better f1-score can be achieved. It is also important to note that the recall was much higher with the linear SVC model (0.96 for linear SVC, 0.56 for random forest)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Key Findings"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We had very consistent results in tests including multiple folds, and similarly consistent metrics between different sampling techniques (under-/over-sampling or none). This indicates that our models did not favor any particular data points, and that our features had been at least mostly appropriately scaled.\n",
    "\n",
    "High recall and low precision was found in both our logistic regression models, as well as our SVC models. Our random forest model, however, had much more even performance metrics, having lower recall than the other models, but a higher precision. The high recall and low precision gave rise to rather poor f1-scores across the board.\n",
    "\n",
    "As we noted when inspecting and transforming our dataset, we found very high correlations between a few of our features. This may have impacted our performance metrics, as well as the convergence time for some models.\n",
    "\n",
    "Though we focused on training with neither under- nor over-sampling, under-sampling seemed to assist performance in some tests."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Possible Flaws and Suggested Revisions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Given the very strong correlations between our features and the generally low performance of our models, it may be worth revisiting this problem with some further data transformations.\n",
    "\n",
    "`estimated_diameter_min` and `estimated_diameter_max` had an essentially perfect positive correlation. These two features also had very strong negative correlations with `absolute_magnitude`. While we noted that these correlations were expected, it may still be worth addressing these in some further tests. Performing PCA transformations may help quite a bit, but we risk losing some interpretability. Averaging `estimated_diameter_min` and `estimated_diameter_max` may also be a valid approach, since `absolute_magnitude` (aka intrinsic luminosity) also factors in reflectivity.\n",
    "\n",
    "I would expect addressing the correlations will provide a much needed performance boost for our linear SVC model, and perhaps our random forest model as well.\n",
    "\n",
    "It would also be interesting to test a combination of random forest and the linear SVC models, especially if they each perform better in different metrics."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## -----------------------------------------"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Revisiting the Problem with PCA"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Preparing the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.preprocessing import PowerTransformer\n",
    "from sklearn.preprocessing import QuantileTransformer\n",
    "\n",
    "\n",
    "dfc2 = df.copy()  # copy our dataframe, so we can apply transformations on the copy rather than the original.\n",
    "\n",
    "mms = MinMaxScaler()\n",
    "ss = StandardScaler()\n",
    "bct = PowerTransformer(method='box-cox')\n",
    "qt = QuantileTransformer(output_distribution='normal', random_state=42)\n",
    "\n",
    "dfc2['absolute_magnitude'] = ss.fit_transform(pd.DataFrame(dfc2['absolute_magnitude']))\n",
    "\n",
    "dfc2['estimated_diameter_min'] = bct.fit_transform(pd.DataFrame(dfc2['estimated_diameter_min']))\n",
    "\n",
    "dfc2['estimated_diameter_max'] = bct.fit_transform(pd.DataFrame(dfc2['estimated_diameter_max']))\n",
    "\n",
    "dfc2['relative_velocity'] = bct.fit_transform(pd.DataFrame(dfc2['relative_velocity']))\n",
    "dfc2['relative_velocity'] = ss.fit_transform(pd.DataFrame(dfc2['relative_velocity']))\n",
    "\n",
    "dfc2['miss_distance'] = qt.fit_transform(pd.DataFrame(dfc2['miss_distance']))\n",
    "\n",
    "if True: # We won't apply min-max prior to PCA\n",
    "    dfc2['absolute_magnitude'] = mms.fit_transform(pd.DataFrame(dfc2['absolute_magnitude']))\n",
    "    dfc2['estimated_diameter_min'] = mms.fit_transform(pd.DataFrame(dfc2['estimated_diameter_min']))\n",
    "    dfc2['estimated_diameter_max'] = mms.fit_transform(pd.DataFrame(dfc2['estimated_diameter_max']))\n",
    "    dfc2['relative_velocity'] = mms.fit_transform(pd.DataFrame(dfc2['relative_velocity']))\n",
    "    dfc2['miss_distance'] = mms.fit_transform(pd.DataFrame(dfc2['miss_distance']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Component 0</th>\n",
       "      <th>Component 1</th>\n",
       "      <th>Component 2</th>\n",
       "      <th>Component 3</th>\n",
       "      <th>Component 4</th>\n",
       "      <th>is_hazardous</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>-0.288078</td>\n",
       "      <td>0.031681</td>\n",
       "      <td>0.000340</td>\n",
       "      <td>0.001239</td>\n",
       "      <td>9.681074e-12</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>-0.358322</td>\n",
       "      <td>0.102696</td>\n",
       "      <td>-0.070710</td>\n",
       "      <td>0.002128</td>\n",
       "      <td>9.843989e-12</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>-0.086201</td>\n",
       "      <td>-0.059823</td>\n",
       "      <td>0.157057</td>\n",
       "      <td>-0.000896</td>\n",
       "      <td>-2.098127e-11</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>-0.176455</td>\n",
       "      <td>0.024596</td>\n",
       "      <td>-0.099932</td>\n",
       "      <td>-0.000764</td>\n",
       "      <td>1.376661e-11</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>-0.034329</td>\n",
       "      <td>0.071460</td>\n",
       "      <td>0.049600</td>\n",
       "      <td>-0.001643</td>\n",
       "      <td>-5.415048e-11</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Component 0  Component 1  Component 2  Component 3   Component 4  \\\n",
       "0    -0.288078     0.031681     0.000340     0.001239  9.681074e-12   \n",
       "1    -0.358322     0.102696    -0.070710     0.002128  9.843989e-12   \n",
       "2    -0.086201    -0.059823     0.157057    -0.000896 -2.098127e-11   \n",
       "3    -0.176455     0.024596    -0.099932    -0.000764  1.376661e-11   \n",
       "4    -0.034329     0.071460     0.049600    -0.001643 -5.415048e-11   \n",
       "\n",
       "   is_hazardous  \n",
       "0             0  \n",
       "1             1  \n",
       "2             0  \n",
       "3             0  \n",
       "4             0  "
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.decomposition import PCA\n",
    "\n",
    "pcat = PCA()\n",
    "pcat.fit(dfc2[feature_cols])\n",
    "X_hat = pd.DataFrame(pcat.transform(dfc2[feature_cols]), index=dfc2.index, columns=[f'Component {i}' for i in range(pcat.n_components_)])\n",
    "dfc_pca = pd.concat([X_hat, dfc2['is_hazardous']], axis=1)\n",
    "dfc_pca.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "We can keep the first 3 components and discard the other 2,\n",
      "keeping >=99.0% of the explained variance!\n"
     ]
    }
   ],
   "source": [
    "from itertools import accumulate\n",
    "\n",
    "threshold = 0.99\n",
    "num = next(i for i, x in enumerate(accumulate(pcat.explained_variance_ratio_), 1) if x >= threshold)\n",
    "print(f'We can keep the first {num} components and discard the other {pcat.n_components_-num},')\n",
    "print(f'keeping >={100 * threshold}% of the explained variance!')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['Component 0', 'Component 1', 'Component 2'], dtype='object')"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "feature_cols = dfc_pca.columns[0:3]\n",
    "feature_cols"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Component 0</th>\n",
       "      <th>Component 1</th>\n",
       "      <th>Component 2</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>-0.288078</td>\n",
       "      <td>0.031681</td>\n",
       "      <td>0.000340</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>-0.358322</td>\n",
       "      <td>0.102696</td>\n",
       "      <td>-0.070710</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>-0.086201</td>\n",
       "      <td>-0.059823</td>\n",
       "      <td>0.157057</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>-0.176455</td>\n",
       "      <td>0.024596</td>\n",
       "      <td>-0.099932</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>-0.034329</td>\n",
       "      <td>0.071460</td>\n",
       "      <td>0.049600</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Component 0  Component 1  Component 2\n",
       "0    -0.288078     0.031681     0.000340\n",
       "1    -0.358322     0.102696    -0.070710\n",
       "2    -0.086201    -0.059823     0.157057\n",
       "3    -0.176455     0.024596    -0.099932\n",
       "4    -0.034329     0.071460     0.049600"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dfc_pca[feature_cols].head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "best params {'C': np.float64(0.00035938136638046257)}\n",
      "best params {'C': np.float64(0.0005994842503189409)}\n",
      "best params {'C': np.float64(0.00035938136638046257)}\n",
      "best params {'C': np.float64(0.00035938136638046257)}\n",
      "best params {'C': np.float64(0.0005994842503189409)}\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1000x600 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1000x800 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from sklearn.svm import LinearSVC\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "model_label = 'linear_svc'\n",
    "\n",
    "svc_lin = LinearSVC(penalty='l2', class_weight='balanced', random_state=42, max_iter=10000)\n",
    "\n",
    "svc_lin_param_grid = {\n",
    "    'C': np.geomspace(1e-5, 1e-3, num=10),\n",
    "}\n",
    "\n",
    "svc_lin_kwargs = {\n",
    "    'estimator': svc_lin, 'param_grid': svc_lin_param_grid, \n",
    "    'scoring': 'f1', 'n_jobs': -1}\n",
    "\n",
    "num_folds = 5\n",
    "sampling = 0\n",
    "# for sampling in range(-1, 2):\n",
    "svc_lin_scores, svc_lin_conf_mat, _ = train_test_results(\n",
    "                                        df_=dfc_pca,\n",
    "                                        num_folds=num_folds,\n",
    "                                        test_size=0.3,\n",
    "                                        model=GridSearchCV,\n",
    "                                        label=model_label,\n",
    "                                        sampling=sampling,\n",
    "                                        **svc_lin_kwargs)\n",
    "\n",
    "plot_performance_metrics(svc_lin_scores, num_folds=num_folds, sampling=sampling)\n",
    "plot_confusion_matrix(svc_lin_conf_mat, num_folds=num_folds, sampling=sampling)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
